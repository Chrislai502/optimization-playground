{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST Dataset\n",
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) # Format (mean, ) every value is a channel\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size = 10, shuffle = True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size = 10, shuffle = True)\n",
    "\n",
    "# Define the device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "class VerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1 = 100, hidden_size_2=100):\n",
    "        super(VerySimpleNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "net = VerySimpleNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [00:15<00:00, 382.47it/s, loss=tensor(inf, grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# Training the loop\n",
    "\n",
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    # Set Total iterations to zero\n",
    "    total_iterations = 0\n",
    "    \n",
    "    # Start the for loop for epochs\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        # Set net to train mode\n",
    "        net.train()\n",
    "        # Set loss and num_iterations to zero\n",
    "        loss, num_iterations = 0, 0\n",
    "        # Have a data iterator using tqdm\n",
    "        data_iter = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "        # if total iterations limit is not none:\n",
    "        if total_iterations_limit is not None:\n",
    "            # Set total_iterations to total_iterations_limit\n",
    "            total_iterations = total_iterations_limit\n",
    "        # Start the for loop for iterator\n",
    "        for x, y in data_iter:\n",
    "            \n",
    "            # Increment iterations and total_iterations\n",
    "            total_iterations += 1\n",
    "            \n",
    "            # Move data and labels to device\n",
    "            x = x.to(device)\n",
    "            y= y.to(device)\n",
    "            # Zero the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = net(x)\n",
    "            # Loss calculation\n",
    "            loss = ce_loss(output, y)\n",
    "            # Perform backpropagation calculation\n",
    "            loss.backward()\n",
    "            # Perform update step\n",
    "            optimizer.step()\n",
    "            \n",
    "            # metrics stuff:\n",
    "            loss_sum += loss\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iter.set_postfix(loss = avg_loss)\n",
    "            \n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "\n",
    "TEMP_MODEL_FILENAME = 'temp_simplenet_ptq.pt'\n",
    "MODEL_FILENAME = \"simplenet_ptq.pt\"\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    # Save the model?\n",
    "    torch.save(model, TEMP_MODEL_FILENAME)\n",
    "    # Print the size in KB using os.path.getsize\n",
    "    print(f\"Model size in KB {os.path.getsize(TEMP_MODEL_FILENAME)/1e3}\")\n",
    "    # Remove the model with os.remove\n",
    "    os.remove(TEMP_MODEL_FILENAME)\n",
    "\n",
    "# If the path exists, \n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    # Load the state dictionaries\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "else:\n",
    "    train(train_loader, net, epochs=1)\n",
    "    # Save the model once the training is done\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Original Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████▉| 999/1000 [00:01<00:00, 751.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n",
      "Average Time per Batch: 0.000211 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Defining the testing loop with average running time calculation\n",
    "def test(model: nn.Module, total_iterations: int = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterations = 0\n",
    "    times = []  # List to store batch times\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # With torch no gradient\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Start timing for this batch\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Move input and labels to device\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Get model output\n",
    "            output = model(x)\n",
    "            \n",
    "            # Calculate accuracy for the batch\n",
    "            for idx, i in enumerate(output):\n",
    "                answer = torch.argmax(i)\n",
    "                if answer == y[idx]:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            # Stop timing for this batch and store it\n",
    "            batch_time = time.time() - start_time\n",
    "            times.append(batch_time)\n",
    "\n",
    "            # Increment iteration count\n",
    "            iterations += 1\n",
    "            if total_iterations == iterations:\n",
    "                break\n",
    "    \n",
    "    # Compute overall accuracy\n",
    "    accuracy = correct / total\n",
    "    avg_time_per_batch = sum(times) / len(times)\n",
    "    \n",
    "    print(f\"Accuracy: {round(accuracy, 3)}\")\n",
    "    print(f\"Average Time per Batch: {round(avg_time_per_batch, 6)} seconds\")\n",
    "\n",
    "# Run the test on original model\n",
    "print(\"Testing Original Model:\")\n",
    "test(net, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 0.0138,  0.0333, -0.0153,  ...,  0.0360,  0.0178,  0.0162],\n",
      "        [-0.0154, -0.0106, -0.0061,  ..., -0.0159, -0.0016, -0.0256],\n",
      "        [-0.0080,  0.0270, -0.0211,  ..., -0.0082,  0.0133,  0.0202],\n",
      "        ...,\n",
      "        [ 0.0246,  0.0283, -0.0064,  ..., -0.0117,  0.0075, -0.0294],\n",
      "        [-0.0184, -0.0103,  0.0217,  ...,  0.0020,  0.0021,  0.0016],\n",
      "        [ 0.0084,  0.0031, -0.0110,  ...,  0.0254, -0.0239, -0.0038]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Printing out weights of the model before quantization\n",
    "print('Weights before quantization')\n",
    "print(net.linear1.weight)\n",
    "print(net.linear1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size in KB 361.839\n"
     ]
    }
   ],
   "source": [
    "# Print size of model before quantization\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:01<00:00, 719.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model before quantization')\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting min-max observers in the model\n",
    "class QuantizedVerySimpleNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(QuantizedVerySimpleNet, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    # Forward\n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "        \n",
    "        # Flatten out imagae\n",
    "        # Quantize inputs\n",
    "        # Forward till end\n",
    "        # Dequantize\n",
    "        # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define net and put it todevide\n",
    "import torch.ao.quantization\n",
    "\n",
    "\n",
    "static_quantized_net = QuantizedVerySimpleNet().to(device)\n",
    "\n",
    "# Copy weights by loading state dict from other model\n",
    "static_quantized_net.load_state_dict(net.state_dict())\n",
    "\n",
    "# Set to eval mode\n",
    "static_quantized_net.eval()\n",
    "\n",
    "# Get Quantization config and run quantization stuff\n",
    "# torch.ao.quantization.default_qconfig\n",
    "from torch.ao.quantization.qconfig import QConfig\n",
    "from torch.ao.quantization.observer import MinMaxObserver\n",
    "import functools\n",
    "config = QConfig(\n",
    "    activation = functools.partial(MinMaxObserver, quant_min=0, quant_max=127),\n",
    "    weight = functools.partial(MinMaxObserver, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric)\n",
    ")\n",
    "\n",
    "static_quantized_net.qconfig = config\n",
    "static_quantized_net = torch.ao.quantization.prepare(static_quantized_net) # Preparing observers\n",
    "torch.ao.quantization.default_qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ao.quantization.qconfig.default_per_channel_qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedVerySimpleNet(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (linear1): Linear(\n",
      "    in_features=784, out_features=100, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (linear2): Linear(\n",
      "    in_features=100, out_features=100, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (linear3): Linear(\n",
      "    in_features=100, out_features=10, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:01<00:00, 749.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Calibrate the model using the test set \n",
    "test(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedVerySimpleNet(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
      "  )\n",
      "  (linear1): Linear(\n",
      "    in_features=784, out_features=100, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=-46.70039367675781, max_val=28.700359344482422)\n",
      "  )\n",
      "  (linear2): Linear(\n",
      "    in_features=100, out_features=100, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=-27.921293258666992, max_val=27.60137939453125)\n",
      "  )\n",
      "  (linear3): Linear(\n",
      "    in_features=100, out_features=10, bias=True\n",
      "    (activation_post_process): MinMaxObserver(min_val=-32.47340393066406, max_val=22.86193084716797)\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_quantized_net = torch.ao.quantization.convert(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0138,  0.0333, -0.0153,  ...,  0.0360,  0.0178,  0.0162],\n",
      "        [-0.0154, -0.0106, -0.0061,  ..., -0.0159, -0.0016, -0.0256],\n",
      "        [-0.0080,  0.0270, -0.0211,  ..., -0.0082,  0.0133,  0.0202],\n",
      "        ...,\n",
      "        [ 0.0246,  0.0283, -0.0064,  ..., -0.0117,  0.0075, -0.0294],\n",
      "        [-0.0184, -0.0103,  0.0217,  ...,  0.0020,  0.0021,  0.0016],\n",
      "        [ 0.0084,  0.0031, -0.0110,  ...,  0.0254, -0.0239, -0.0038]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[ 0.0132,  0.0352, -0.0132,  ...,  0.0352,  0.0176,  0.0176],\n",
      "        [-0.0132, -0.0088, -0.0044,  ..., -0.0176,  0.0000, -0.0264],\n",
      "        [-0.0088,  0.0264, -0.0220,  ..., -0.0088,  0.0132,  0.0220],\n",
      "        ...,\n",
      "        [ 0.0264,  0.0264, -0.0044,  ..., -0.0132,  0.0088, -0.0308],\n",
      "        [-0.0176, -0.0088,  0.0220,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0088,  0.0044, -0.0132,  ...,  0.0264, -0.0220, -0.0044]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(net.linear1.weight)\n",
    "print('')\n",
    "print(f'Dequantized weights: ')\n",
    "print(torch.dequantize(static_quantized_net.linear1.weight()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model after quantization\n",
      "Model size in KB 95.613\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model after quantization')\n",
    "print_size_of_model(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:01<00:00, 759.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing the model after quantization')\n",
    "test(static_quantized_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicQuantizedLinear(in_features=784, out_features=100, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "DynamicQuantizedLinear(in_features=100, out_features=100, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "tensor([[ 0.0132,  0.0352, -0.0132,  ...,  0.0352,  0.0176,  0.0176],\n",
      "        [-0.0132, -0.0088, -0.0044,  ..., -0.0176,  0.0000, -0.0264],\n",
      "        [-0.0088,  0.0264, -0.0220,  ..., -0.0088,  0.0132,  0.0220],\n",
      "        ...,\n",
      "        [ 0.0264,  0.0264, -0.0044,  ..., -0.0132,  0.0088, -0.0308],\n",
      "        [-0.0176, -0.0088,  0.0220,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0088,  0.0044, -0.0132,  ...,  0.0264, -0.0220, -0.0044]],\n",
      "       size=(100, 784), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.004404082428663969,\n",
      "       zero_point=0)\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Post-training Quantization\n",
    "\n",
    "from torch.quantization import default_dynamic_qconfig\n",
    "model_fp32 = VerySimpleNet()\n",
    "\n",
    "# Method # 1 to do it\n",
    "qconfig_spec = {\n",
    "    # Apply int8 to all layers\n",
    "    torch.nn.Linear: torch.quantization.default_dynamic_qconfig,\n",
    "    # For layer2, we use float16 quantization for weights\n",
    "    # \"linear2\": torch.quantization.float16_dynamic_qconfig\n",
    "}\n",
    "\n",
    "net.eval()\n",
    "\n",
    "dynamic_quantized_model = torch.quantization.quantize_dynamic(\n",
    "    net,\n",
    "    qconfig_spec= qconfig_spec,\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "# # Method #2 to do it\n",
    "# quantized_model = torch.quantization.quantize_dynamic(\n",
    "#     model_fp32,\n",
    "#     qconfig_spec={torch.nn.Linear},\n",
    "#     dtype=torch.qint8,\n",
    "#     inplace=False\n",
    "# )\n",
    "print(dynamic_quantized_model.linear1)\n",
    "print(dynamic_quantized_model.linear2)\n",
    "print(dynamic_quantized_model.linear1.weight())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (fc): MyLinearLayer(in_features=784, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# On the side, mapping can be used as such:\n",
    "import torch\n",
    "import torch.nn.quantized.dynamic as nnqd\n",
    "\n",
    "# Assume you have a custom linear layer\n",
    "class MyLinearLayer(torch.nn.Linear):\n",
    "    pass\n",
    "\n",
    "# Create a model with MyLinearLayer\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = MyLinearLayer(28*28, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "# Define the mapping to replace MyLinearLayer with dynamically quantized Linear\n",
    "mapping = {\n",
    "    MyLinearLayer: nnqd.Linear  # Map MyLinearLayer to torch.nn.quantized.dynamic.Linear\n",
    "}\n",
    "    \n",
    "    \n",
    "# Apply dynamic quantization\n",
    "model = MyModel()\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, qconfig_spec={torch.nn.Linear}, mapping=mapping, inplace=False\n",
    ")\n",
    "\n",
    "print(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Original Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████▉| 999/1000 [00:01<00:00, 757.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954\n",
      "Average Time per Batch: 0.000215 seconds\n",
      "Testing Dynamic Quantized Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████▉| 999/1000 [00:01<00:00, 775.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953\n",
      "Average Time per Batch: 0.00024 seconds\n",
      "\n",
      "Testing Static Quantized Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████▉| 999/1000 [00:01<00:00, 784.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953\n",
      "Average Time per Batch: 0.000247 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the test on original model\n",
    "print(\"Testing Original Model:\")\n",
    "test(net, 1000)\n",
    "\n",
    "# Test dynamic quantized model\n",
    "print(\"Testing Dynamic Quantized Model:\")\n",
    "test(dynamic_quantized_model, 1000)\n",
    "\n",
    "# Test static quantized model\n",
    "print(\"\\nTesting Static Quantized Model:\")\n",
    "test(static_quantized_net, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
